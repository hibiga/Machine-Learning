{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from operator import itemgetter\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "import tensorflow.compat.v1 as tf\n",
    "from tensorflow import keras\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D, BatchNormalization\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import regularizers, optimizers\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import time"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def unpickle() :\n",
    "    for file in os.listdir(\"datataset\") :\n",
    "        if file == \"batches.meta\" :\n",
    "            continue\n",
    "        file_name = \"datataset/\" + file\n",
    "        with open(file_name, 'rb') as fo :\n",
    "            dict = pickle.load(fo, encoding='latin1')\n",
    "        data = np.array([dict['data']])\n",
    "        data = data.reshape((len(dict['data']), 3, 32, 32)).transpose(0, 2, 3, 1)\n",
    "        label = [dict['labels']]\n",
    "\n",
    "        return data, label"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def load_label_names():\n",
    "    return ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def vision_data() :\n",
    "    features, labels = unpickle()\n",
    "    label_names = load_label_names()\n",
    "\n",
    "    label_counts = dict(zip(*np.unique(labels, return_counts=True)))\n",
    "    data_list = []\n",
    "    num = 6000\n",
    "    for key, value in label_counts.items():\n",
    "        print('Label Counts of [{}]({}) : {}'.format(key, label_names[key].upper(), num))\n",
    "        data_list.append([num, key])\n",
    "\n",
    "\n",
    "    data_list = sorted(data_list, key=itemgetter(0))\n",
    "    features_sorted = []\n",
    "    importance_sorted = []\n",
    "    for i in data_list :\n",
    "        features_sorted += [i[1]]\n",
    "        importance_sorted += [i[0]]\n",
    "#     print(len(importance_sorted), importance_sorted, features_sorted)\n",
    "\n",
    "    p1 = plt.barh(range(len(importance_sorted)), importance_sorted)\n",
    "    plt.bar_label(p1)\n",
    "    plt.title(\"Distribution des données dans chaque classe\")\n",
    "    plt.yticks(range(len(importance_sorted)), features_sorted)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "vision_data()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# features, labels = read_data(label_ids=label_ids)\n",
    "features, labels = unpickle()\n",
    "label_names = load_label_names()\n",
    "\n",
    "# print(labels[1])\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "for i in range(25):\n",
    "    plt.subplot(5, 5, i + 1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(features[i], cmap=plt.cm.binary)\n",
    "#         print(labels[0][i])\n",
    "\n",
    "    nom = label_names[labels[0][i]]\n",
    "    plt.title(nom)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def unpickle_2classes(label_ids: list) :\n",
    "    for file in os.listdir(\"datataset\") :\n",
    "        if file == \"batches.meta\" :\n",
    "            continue\n",
    "        file_name = \"datataset/\" + file\n",
    "        with open(file_name, 'rb') as fo :\n",
    "            dict = pickle.load(fo, encoding='latin1')\n",
    "\n",
    "        wanted = [i for i, v in enumerate(dict['labels']) if v in label_ids]\n",
    "        data = np.array([dict['data'][x] for x in wanted])\n",
    "        data = data.reshape((len(data), 3, 32, 32)).transpose(0, 2, 3, 1)\n",
    "        label = [dict['labels'][x] for x in wanted]\n",
    "\n",
    "        return data, label"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def read_data(label_ids: list):\n",
    "    all_desired_data = []\n",
    "    all_desired_label = []\n",
    "\n",
    "    for file in os.listdir('datataset'):\n",
    "        file_name = \"datataset/\" + file\n",
    "        if file == \"batches.meta\":\n",
    "            continue\n",
    "        with open(file_name, 'rb') as fo:\n",
    "            data_dict = pickle.load(fo, encoding='bytes')\n",
    "\n",
    "        desired_data_ids = [i for i, v in enumerate(data_dict[b'labels']) if v in label_ids]\n",
    "\n",
    "        desired_data = [data_dict[b'data'][x] for x in desired_data_ids]\n",
    "        desired_label = [data_dict[b'labels'][x] for x in desired_data_ids]\n",
    "        all_desired_data += desired_data\n",
    "        all_desired_label += desired_label\n",
    "\n",
    "    all_desired_data = np.array(all_desired_data)\n",
    "    all_desired_data = all_desired_data.reshape((len(all_desired_data), 3, 32, 32)).transpose(0, 2, 3, 1)\n",
    "\n",
    "\n",
    "    return all_desired_data, all_desired_label\n",
    "\n",
    "label_ids = [2, 5]\n",
    "features, labels = read_data(label_ids=label_ids)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "features, labels = read_data(label_ids=label_ids)\n",
    "# features, labels = unpickle()\n",
    "label_names = load_label_names()\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "for i in range(25):\n",
    "    plt.subplot(5, 5, i + 1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(features[i], cmap=plt.cm.binary)\n",
    "#         print(labels[0][i])\n",
    "\n",
    "    nom = label_names[labels[i]]\n",
    "    plt.title(nom)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def changer_name(labels) :\n",
    "    for i in range(len(labels)) :\n",
    "    #     print(i)\n",
    "        if labels[i] == 2 :\n",
    "    #         print(\"oui\")\n",
    "            labels[i] = 0 #oiseau devient 0\n",
    "        elif labels[i] == 5 :\n",
    "            labels[i] = 1 #chien devient 1\n",
    "    return labels"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "labels = changer_name(labels)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "for i in range(25):\n",
    "    plt.subplot(5, 5, i + 1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(features[i], cmap=plt.cm.binary)\n",
    "#     print(labels[i])\n",
    "    plt.title(labels[i])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def normalize(x):\n",
    "    min_val = np.min(x)\n",
    "    max_val = np.max(x)\n",
    "    x = (x-min_val) / (max_val-min_val)\n",
    "    x = np.array(x)\n",
    "    return x"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def split_data(x, y):\n",
    "\n",
    "    x_train_validate, x_test, y_train_validate, y_test = train_test_split(x, y, test_size=0.15, random_state=0, stratify=y)\n",
    "    x_train, x_validate, y_train, y_validate = train_test_split(x_train_validate, y_train_validate, test_size=(15*len(x))/(100*len(x_train_validate)+1), random_state=0, stratify=y_train_validate)\n",
    "    return [x_train, y_train], [x_test, y_test], [x_validate, y_validate]\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def preparation(features, labels, label_ids: list):\n",
    "\n",
    "    features, labels = read_data(label_ids=label_ids)\n",
    "#     labels = changer_name(labels)\n",
    "    train_origin, test_origin, validate_origin = split_data(features, labels)\n",
    "\n",
    "    x_train = normalize(train_origin[0])\n",
    "    x_test = normalize(test_origin[0])\n",
    "    x_validate = normalize(validate_origin[0])\n",
    "\n",
    "#     y_train = keras.utils.to_categorical(train_origin[1], 1)\n",
    "#     y_test = keras.utils.to_categorical(test_origin[1], 1)\n",
    "#     y_validate = keras.utils.to_categorical(validate_origin[1], 1)\n",
    "\n",
    "    y_train = np.array(train_origin[1])\n",
    "    y_test = np.array(test_origin[1])\n",
    "    y_validate = np.array(validate_origin[1])\n",
    "\n",
    "    nsamples = y_train.shape\n",
    "    y_train = y_train.reshape(int(nsamples[0]),1)\n",
    "\n",
    "    nsamples = y_test.shape\n",
    "    y_test = y_test.reshape(int(nsamples[0]),1)\n",
    "\n",
    "    nsamples = y_validate.shape\n",
    "    y_validate = y_validate.reshape(int(nsamples[0]),1)\n",
    "\n",
    "    print('shape X train : ', x_train.shape)\n",
    "    print('shape X test : ', x_test.shape)\n",
    "    print('shape X validate : ', x_validate.shape)\n",
    "    print('shape Y train : ', y_train.shape)\n",
    "    print('shape Y test : ', y_test.shape)\n",
    "    print('shape Y validate : ', y_validate.shape)\n",
    "\n",
    "    return [x_train, y_train], [x_test, y_test], [x_validate, y_validate]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train, test, validate = preparation(features, labels, label_ids = [2, 5])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train, test, validate = preparation(features, labels, label_ids = [2, 5])\n",
    "num_classes = 6\n",
    "\n",
    "y_train = keras.utils.to_categorical(train[1], num_classes)\n",
    "y_test = keras.utils.to_categorical(test[1], num_classes)\n",
    "y_validate = keras.utils.to_categorical(validate[1], num_classes)\n",
    "\n",
    "x_train = train[0]\n",
    "x_test = test[0]\n",
    "x_validate = validate[0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "len"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def pre_graph(data) :\n",
    "    features_sorted = []\n",
    "    importance_sorted = []\n",
    "    oiseau = 0\n",
    "    chien = 0\n",
    "    for i in data[1] :\n",
    "        if i[0] == 2 :\n",
    "            oiseau += 1\n",
    "        else :\n",
    "            chien += 1\n",
    "    importance_sorted = [oiseau, chien]\n",
    "    features_sorted = [\"oiseau\", \"chien\"]\n",
    "\n",
    "    return importance_sorted, features_sorted"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "c = ['black', 'orange']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "importance_sorted, features_sorted = pre_graph(train)\n",
    "p2 = plt.bar(range(len(importance_sorted)), importance_sorted, color = c)\n",
    "plt.bar_label(p2)\n",
    "plt.title(\"Distribution des train data : 70%\")\n",
    "plt.xticks(range(len(importance_sorted)), features_sorted)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "importance_sorted, features_sorted = pre_graph(test)\n",
    "p3 = plt.bar(range(len(importance_sorted)), importance_sorted, color = c)\n",
    "plt.bar_label(p3)\n",
    "plt.title(\"Distribution des test data : 15%\")\n",
    "plt.xticks(range(len(importance_sorted)), features_sorted)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# plt.figsize=(20,10)\n",
    "importance_sorted, features_sorted = pre_graph(validate)\n",
    "p4 = plt.bar(range(len(importance_sorted)), importance_sorted, color = c)\n",
    "plt.bar_label(p4)\n",
    "plt.title(\"Distribution pour les validate data : 15%\")\n",
    "plt.xticks(range(len(importance_sorted)), features_sorted)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Regression linéaire"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def mettre_list (data) :\n",
    "    listes = []\n",
    "    for i in range(len(data)) :\n",
    "        listes.append(int(data[i]))\n",
    "\n",
    "    return listes\n",
    "\n",
    "def changer_name(labels) :\n",
    "    for i in range(len(labels)) :\n",
    "    #     print(i)\n",
    "        if labels[i] == 2 :\n",
    "    #         print(\"oui\")\n",
    "            labels[i] = 0 #oiseau devient 0\n",
    "        elif labels[i] == 5 :\n",
    "            labels[i] = 1 #chien devient 1\n",
    "    return labels"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "x_train = train[0].reshape(train[0].shape[0], 32*32*3)\n",
    "x_test = test[0].reshape(test[0].shape[0], 32*32*3)\n",
    "y_train = mettre_list(train[1])\n",
    "y_test = mettre_list(test[1])\n",
    "# print(y_train)\n",
    "y_train = changer_name(y_train)\n",
    "y_test = changer_name(y_test)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "regressor = LinearRegression()\n",
    "hist2 = regressor.fit(x_train, y_train)\n",
    "end_time = time.time()\n",
    "\n",
    "print(regressor.intercept_)\n",
    "pd.DataFrame(regressor.coef_)\n",
    "print(pd.DataFrame(regressor.coef_))\n",
    "\n",
    "elapsed_time_rl = end_time - start_time\n",
    "elapsed_time_rl = round(elapsed_time_rl, 3)\n",
    "print(\"Elapsed time:\", elapsed_time_rl)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "y_pred = regressor.predict(x_test)\n",
    "y_pred = [np.round(x) for x in y_pred]\n",
    "\n",
    "\n",
    "for i in range(len(y_pred)) :\n",
    "    if y_pred[i] == -1.0 :\n",
    "        y_pred[i] = 1\n",
    "    elif y_pred[i] == -0.0 :\n",
    "        y_pred[i] = 0\n",
    "\n",
    "df = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred})\n",
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))\n",
    "print('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))\n",
    "# print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))\n",
    "# print(\"Explain variance score =\", metrics.explained_variance_score(y_test, y_pred))\n",
    "print(\"R2 score =\", metrics.r2_score(y_test, y_pred))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "metrics.accuracy_score(y_test, y_pred)\n",
    "\n",
    "rl = metrics.accuracy_score(y_test, y_pred)\n",
    "\n",
    "rl"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Knn"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_accuracy(predictions, actual):\n",
    "    difference = predictions - actual\n",
    "    number_predictions = predictions.shape[0]\n",
    "    number_incorrect = np.count_nonzero(difference)\n",
    "    number_correct = number_predictions - number_incorrect\n",
    "    accuracy = number_correct / number_predictions\n",
    "    return accuracy"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "classifier = KNeighborsClassifier(n_neighbors=5)\n",
    "accuracies = []\n",
    "kf = KFold(n_splits=5, shuffle=True)\n",
    "x_train = train[0].reshape(train[0].shape[0], 32*32*3)\n",
    "x_test = test[0].reshape(test[0].shape[0], 32*32*3)\n",
    "y_train = mettre_list(train[1])\n",
    "y_test = mettre_list(test[1])\n",
    "# print(y_train)\n",
    "y_train = changer_name(y_train)\n",
    "y_test = changer_name(y_test)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "classifier.fit(x_train, y_train)\n",
    "y_predict = classifier.predict(x_test)\n",
    "accuracy = get_accuracy(y_predict, y_test)\n",
    "accuracies.append(accuracy)\n",
    "end_time = time.time()\n",
    "\n",
    "mean_accuracy = np.array(accuracies).mean()\n",
    "mean_accuracy = round(mean_accuracy, 3)\n",
    "print(\"Mean accuracy:\", mean_accuracy)\n",
    "\n",
    "knn = mean_accuracy"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "elapsed_time_knn = end_time - start_time\n",
    "elapsed_time_knn = round(elapsed_time_knn, 3)\n",
    "print(\"Elapsed time:\", elapsed_time_knn)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## CNN\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train, test, validate = preparation(features, labels, label_ids = [2, 5])\n",
    "num_classes = 6\n",
    "\n",
    "y_train = keras.utils.to_categorical(train[1], num_classes)\n",
    "y_test = keras.utils.to_categorical(test[1], num_classes)\n",
    "y_validate = keras.utils.to_categorical(validate[1], num_classes)\n",
    "\n",
    "x_train = train[0]\n",
    "x_test = test[0]\n",
    "x_validate = validate[0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def covnet(baseMapNum = 64, weight_decay = 1e-4):\n",
    "    keras.backend.clear_session()\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(baseMapNum, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay), input_shape=x_train.shape[1:]))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(baseMapNum, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Conv2D(2*baseMapNum, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(2*baseMapNum, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.3))\n",
    "\n",
    "    model.add(Conv2D(4*baseMapNum, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(4*baseMapNum, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.45))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(6, activation='softmax'))\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = covnet()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    featurewise_center=False,\n",
    "    samplewise_center=False,\n",
    "    featurewise_std_normalization=False,\n",
    "    samplewise_std_normalization=False,\n",
    "    zca_whitening=False,\n",
    "    zoom_range=[0.8,1.4],\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=False\n",
    "    )\n",
    "datagen.fit(train[0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "optz = keras.optimizers.RMSprop(learning_rate=0.0007,decay=1e-6)\n",
    "batch_size = 64\n",
    "steps_epoch=2*x_train.shape[0]\n",
    "epochs = 30\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optz, metrics=['accuracy'])\n",
    "callback = [keras.callbacks.EarlyStopping(monitor=\"val_loss\", mode=\"min\", patience=4, restore_best_weights=True)]\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Fit the model on the batches generated by datagen.flow().\n",
    "hist1 = model.fit(datagen.flow(x_train, y_train, batch_size=batch_size),\n",
    "                    validation_data=(x_validate, y_validate),\n",
    "                    epochs=epochs, verbose=0, callbacks=callback)\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "model.save_weights('cifar10_ep{}.h5'.format(len(hist1.history['loss'])))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "elapsed_time_cnn = end_time - start_time\n",
    "elapsed_time_cnn = round(elapsed_time_cnn, 3)\n",
    "print(\"Elapsed time:\", elapsed_time_cnn)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def plot_model_result(model_fit):\n",
    "    plt.subplot(2, 1, 1)\n",
    "    plt.plot(model_fit.history['accuracy'])\n",
    "    plt.title('model accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train'], loc='lower right')\n",
    "\n",
    "    plt.subplot(2, 1, 2)\n",
    "    plt.plot(model_fit.history['loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train'], loc='upper right')\n",
    "    plt.tight_layout()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "hist1.history['accuracy']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_model_result(hist1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "acc = hist1.history['accuracy']\n",
    "print(\"Taux de réussite de : \", max(acc))\n",
    "cnn = max(acc)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Comparaison"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# knn\n",
    "# rl = 0.5\n",
    "# cnn = 0.80\n",
    "final = []\n",
    "\n",
    "final = np.array([[\"cnn\", cnn], [\"regression linéaire\", rl], [\"knn\", knn]])\n",
    "df = pd.DataFrame(final, columns=['Model', 'Accuracy'])\n",
    "df = df.sort_values(by=\"Accuracy\", ascending=True)\n",
    "df['Accuracy']=df['Accuracy'].astype(float)\n",
    "ax = df.plot.barh(x='Model', y='Accuracy')\n",
    "ax.set_xscale('log')\n",
    "ax.bar_label(ax.containers[0])\n",
    "plt.title(\"Comparaison des taux de précisions des modèles\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "final = []\n",
    "final = np.array([[\"cnn\", elapsed_time_cnn], [\"regression linéaire\", elapsed_time_rl], [\"knn\", elapsed_time_knn]])\n",
    "df = pd.DataFrame(final, columns=['Model', 'Temps'])\n",
    "df = df.sort_values(by=\"Temps\", ascending=True)\n",
    "df['Temps']=df['Temps'].astype(float)\n",
    "ax = df.plot.barh(x='Model', y='Temps')\n",
    "ax.set_xscale('log')\n",
    "ax.bar_label(ax.containers[0])\n",
    "plt.title(\"Comparaison des temps d'exécution des modèles (en secondes)\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(model_to_plot, test_data):\n",
    "    y_pred = model_to_plot.predict(test_data[0])\n",
    "    y_pred_label = np.argmax(y_pred, 1)\n",
    "    y_test_label = list(test_data[1])\n",
    "\n",
    "\n",
    "\n",
    "    mat = confusion_matrix(y_test_label, y_pred_label)\n",
    "    cmd = ConfusionMatrixDisplay(confusion_matrix=mat.T)\n",
    "    fig, ax1 = plt.subplots(figsize=(8, 8))\n",
    "    cmd.plot(cmap=plt.cm.Blues, ax=ax1)\n",
    "\n",
    "    return y_pred_label, y_test_label"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "Y_pred, Y_test = plot_confusion_matrix(model, test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def display_errors(label_pred, label_test, data_test):\n",
    "    label_test = np.argmax(label_test, 1)\n",
    "    label_test = label_test\n",
    "    errors = (label_pred - label_test != 0)\n",
    "    Y_pred_errors_class = label_pred[errors]  # [1, 2, 3, 5, 9, ....]\n",
    "    Y_test_errors_class = label_test[errors]  # [2, 2, 3, 5, 9, ....]\n",
    "    X_test_errors = data_test[errors]\n",
    "    fig, ax3 = plt.subplots(1, 1, figsize=(10, 7))\n",
    "\n",
    "    error_index = np.where(Y_test_errors_class == 2)\n",
    "    error_index = np.random.choice(error_index[0], size=1)\n",
    "#     print(X_test_errors[error_index][0])\n",
    "    ax3.imshow((X_test_errors[error_index]).reshape((32, 32, 3)), cmap=plt.cm.binary)\n",
    "    ax3.set_title(\"Predicted label :{}\\nTrue label :{}\".format(Y_pred_errors_class[error_index], Y_test_errors_class[error_index]))\n",
    "\n",
    "#     print(Y_test_errors_class)\n",
    "#     for row in range(nrows):\n",
    "#         for col in range(ncols):\n",
    "#             error_index = np.where(Y_test_errors_class == ncols * row + col)\n",
    "#             print(error_index)\n",
    "#             if error_index and len(error_index[0]) != 0:\n",
    "#                 error_index = np.random.choice(error_index[0], size=1)\n",
    "#             else:\n",
    "#                 continue\n",
    "#             ax3[row, col].imshow((X_test_errors[error_index]).reshape((32, 32)), cmap=plt.cm.binary)\n",
    "#             ax3[row, col].set_title(\"Predicted label :{}\\nTrue label :{}\".format(Y_pred_errors_class[error_index], Y_test_errors_class[error_index]))\n",
    "#             n += 1\n",
    "\n",
    "display_errors(Y_pred, y_test, x_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def display_errors5(label_pred, label_test, data_test):\n",
    "    label_test = np.argmax(label_test, 1)\n",
    "    label_test = label_test\n",
    "    errors = (label_pred - label_test != 0)\n",
    "    Y_pred_errors_class = label_pred[errors]  # [1, 2, 3, 5, 9, ....]\n",
    "    Y_test_errors_class = label_test[errors]  # [2, 2, 3, 5, 9, ....]\n",
    "    X_test_errors = data_test[errors]\n",
    "    fig, ax3 = plt.subplots(1, 1, figsize=(10, 7))\n",
    "\n",
    "    error_index = np.where(Y_test_errors_class == 5)\n",
    "    error_index = np.random.choice(error_index[0], size=1)\n",
    "#     print(X_test_errors[error_index][0])\n",
    "    ax3.imshow((X_test_errors[error_index]).reshape((32, 32, 3)), cmap=plt.cm.binary)\n",
    "    ax3.set_title(\"Predicted label :{}\\nTrue label :{}\".format(Y_pred_errors_class[error_index], Y_test_errors_class[error_index]))\n",
    "\n",
    "\n",
    "display_errors5(Y_pred, y_test, x_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}